{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часть материала украдена из курса \"Глубинное обучение\" ФКН ВШЭ https://www.hse.ru/ba/ami/courses/205504078.html, за что им большое спасибо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Актуальная версия этого ноутбука обретается по адресу\n",
    "https://github.com/nadiinchi/dl_labs/blob/master/lab_pytorch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Устанавливаем pytorch\n",
    "\n",
    "## Linux/OSX\n",
    "\n",
    "\n",
    "На оффсайте http://pytorch.org/ надо выбрать подходящую конфигурацию и скачать.\n",
    "\n",
    "Версию python можно узнать в терминале:\n",
    "```\n",
    "python --version\n",
    "```\n",
    "\n",
    "\n",
    "## Windows without GPU\n",
    "\n",
    "Проще всего поставить при помощи конды:\n",
    "```\n",
    "conda install -c peterjc123 pytorch\n",
    "```\n",
    "\n",
    "## Windows with GPU\n",
    "\n",
    "Смотрите https://github.com/peterjc123/pytorch-scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![img](https://s1.postimg.org/6fl45xnvnj/pytorch-logo-dark.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :\n",
      " [[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n",
      "add 5 :\n",
      "[[ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]\n",
      " [17 18 19 20]]\n",
      "X*X^T  :\n",
      " [[ 14  38  62  86]\n",
      " [ 38 126 214 302]\n",
      " [ 62 214 366 518]\n",
      " [ 86 302 518 734]]\n",
      "mean over cols :\n",
      "[  1.5   5.5   9.5  13.5]\n",
      "cumsum of cols :\n",
      "[[ 0  1  2  3]\n",
      " [ 4  6  8 10]\n",
      " [12 15 18 21]\n",
      " [24 28 32 36]]\n"
     ]
    }
   ],
   "source": [
    "# numpy world\n",
    "\n",
    "x = np.arange(16).reshape(4, 4)\n",
    "\n",
    "print(\"X :\\n %s\" % x)\n",
    "print(\"add 5 :\\n%s\" % (x + 5))\n",
    "print(\"X*X^T  :\\n\", np.dot(x, x.T))\n",
    "print(\"mean over cols :\\n%s\" % (x.mean(axis=-1)))\n",
    "print(\"cumsum of cols :\\n%s\" % (np.cumsum(x, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of y: <class 'torch.Tensor'>\n",
      "Type of y <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# pytorch world\n",
    "\n",
    "x = np.arange(16).reshape(4, 4)\n",
    "\n",
    "y = torch.from_numpy(x)\n",
    "print('Type of y:', type(y))\n",
    "y = torch.from_numpy(x).type(torch.FloatTensor)\n",
    "print('Type of y', type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of x: <class 'torch.Tensor'>\n",
      "X :\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "add 5 :\n",
      "tensor([[ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12],\n",
      "        [13, 14, 15, 16],\n",
      "        [17, 18, 19, 20]])\n",
      "X*X^T  :\n",
      " tensor([[ 14,  38,  62,  86],\n",
      "        [ 38, 126, 214, 302],\n",
      "        [ 62, 214, 366, 518],\n",
      "        [ 86, 302, 518, 734]])\n",
      "mean over cols :\n",
      " tensor([ 1.5000,  5.5000,  9.5000, 13.5000])\n",
      "cumsum of cols :\n",
      " tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  6,  8, 10],\n",
      "        [12, 15, 18, 21],\n",
      "        [24, 28, 32, 36]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0,16).view(4,4)\n",
    "print('Type of x:', type(x))\n",
    "\n",
    "print(\"X :\\n%s\" % x)\n",
    "print(\"add 5 :\\n%s\" % (x + 5))\n",
    "print(\"X*X^T  :\\n\", torch.matmul(x, x.transpose(1, 0)))\n",
    "print(\"mean over cols :\\n\", torch.mean(x.float(), dim=-1))\n",
    "print(\"cumsum of cols :\\n\", torch.cumsum(x, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy vs Pytorch\n",
    "\n",
    "Numpy и Pytorch не требуют описания статического графа вычислений. \n",
    "\n",
    "Можно отлаживаться с помощью pdb или просто print.\n",
    "\n",
    "API несколько различается:\n",
    "\n",
    "```\n",
    "x.reshape([1,2,8]) -> x.view(1,2,8)\n",
    "x.sum(axis=-1) -> x.sum(dim=-1)\n",
    "x.astype('int64') -> x.type(torch.LongTensor)\n",
    "```\n",
    "\n",
    "\n",
    "Легко конвертировать между собой:\n",
    "\n",
    "```\n",
    "torch.from_numpy(npx) -- вернет Tensor\n",
    "tt.numpy() -- вернет Numpy Array\n",
    "```\n",
    "\n",
    "\n",
    "Если что:\n",
    "- смотрите документацию\n",
    "- гуглите (Stackoverflow/tutorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(0, 2 * np.pi, 16)\n",
    "\n",
    "# Mini-task: compute a vector of sin^2(x) + cos^2(x)\n",
    "out = torch.sin(x)**2 + torch.cos(x)**2\n",
    "\n",
    "print(out.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-place operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда работаем с большими массивами, память надо экономить.\n",
    "Некоторые операции происходят с созданием нового объекта – результата вычислений,\n",
    "некоторые изменяют данный объект (in-place операции).\n",
    "В pytorch обычно эти операции различаются добавлением подчеркивания:\n",
    "```\n",
    "x.exp()   # not-in-place operation\n",
    "x.exp_()  # in-place operation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not-in-place:\n",
      "\tx.exp():\t\t [  1.           2.71828175   7.38905621  20.08553696]\n",
      "\tx:\t\t\t [ 0.  1.  2.  3.]\n",
      "In-place:\n",
      "\tx.exp_():\t\t [  1.           2.71828175   7.38905621  20.08553696]\n",
      "\tx after x.exp_():\t [  1.           2.71828175   7.38905621  20.08553696]\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4).float()\n",
    "print('Not-in-place:')\n",
    "print('\\tx.exp():\\t\\t', x.exp().numpy())\n",
    "print('\\tx:\\t\\t\\t', x.numpy())\n",
    "print('In-place:')\n",
    "print('\\tx.exp_():\\t\\t', x.exp_().numpy())\n",
    "print('\\tx after x.exp_():\\t', x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [4 6]]\n",
      "[[0 2]\n",
      " [4 6]]\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 4).view(2, 2)\n",
    "y = torch.arange(4, 8).view(2, 2)\n",
    "z = torch.arange(8, 12).view(2, 2)\n",
    "\n",
    "# Not-in-place:\n",
    "u = x + 2 * y - z    # 3 array allocations?\n",
    "print(u.numpy())\n",
    "\n",
    "# In-place\n",
    "u = y.clone()        # 1 array allocation\n",
    "u.mul_(2)\n",
    "u.add_(x)\n",
    "u.sub_(z)\n",
    "print(u.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting на pytorch (аналогично numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "b: tensor([[1., 0., 1., 0.]])\n",
      "a + b: tensor([[2., 1., 2., 1.],\n",
      "        [2., 1., 2., 1.],\n",
      "        [2., 1., 2., 1.],\n",
      "        [3., 2., 3., 2.]])\n",
      "c: tensor([[-0.1814,  0.7098,  2.1944,  0.4785],\n",
      "        [-1.0664, -1.0232, -0.4976, -0.7068],\n",
      "        [-1.0245,  0.3093, -0.3695, -0.5685],\n",
      "        [-0.2491,  0.8502,  0.9176,  0.9024]])\n",
      "b + c: tensor([[ 0.8186,  0.7098,  3.1944,  0.4785],\n",
      "        [-0.0664, -1.0232,  0.5024, -0.7068],\n",
      "        [-0.0245,  0.3093,  0.6305, -0.5685],\n",
      "        [ 0.7509,  0.8502,  1.9176,  0.9024]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([1, 1, 1, 2]).view(4, 1)\n",
    "b = torch.Tensor([1, 0, 1, 0]).view(1, 4)\n",
    "c = torch.randn(16).view(4, 4)\n",
    "print('a:', a)\n",
    "print('b:', b)\n",
    "print('a + b:', a + b)\n",
    "print('c:', c)\n",
    "print('b + c:', b + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более подробную информацию можно найти на http://pytorch.org/docs/master/notes/broadcasting.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с тензорами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дано 100 объектов, каждый из которых описывается 10-мерным вектором, и 5 точек, каждая из которых также задается 10-мерным вектором. Объекты лежат в матрице X, точки – в матрице Y.\n",
    "\n",
    "Надо для каждого объекта из X найти индекс ближайшей точки из Y только с помощью операций над тензорами\n",
    "(нельзя использовать циклы, list comprehensions, рекурсию, etc,\n",
    "потому что решение с ними будет работать в несколько раз или на несколько порядков медленнее)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = torch.randn(100, 10)\n",
    "Y = torch.randn(5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение с семинара:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 1, 1, 2, 1, 1, 2, 4, 2, 4, 1, 3, 4, 0, 4, 1, 3, 0, 3, 2, 2,\n",
       "       3, 3, 0, 0, 1, 1, 4, 3, 1, 1, 3, 2, 1, 0, 0, 2, 2, 3, 1, 1, 1, 3, 1,\n",
       "       1, 1, 0, 3, 2, 0, 0, 1, 0, 0, 0, 2, 2, 4, 0, 3, 0, 1, 1, 2, 4, 2, 1,\n",
       "       3, 1, 2, 0, 3, 3, 0, 4, 0, 4, 1, 1, 1, 2, 3, 2, 1, 4, 0, 2, 1, 4, 0,\n",
       "       1, 0, 2, 4, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((X.view(100, 1, 10) - Y.view(1, 5, 10)) ** 2).sum(dim=-1).min(dim=-1)[1].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это решение плохо тем, что в качестве промежуточного результата вычилений в нем присутствует трехмерный тензор,\n",
    "который занимает $O(NMD)$ памяти, где N – число объектов, M – число точек, D – размерность пространства."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Внимание, задача!\n",
    "Утверждается, что есть другое решение с такой же скоростью работы,\n",
    "но использующее $O(NM)$ памяти для результатов промежуточных вычислений.\n",
    "Предлагается найти его.\n",
    "\n",
    "Подсказка: найти матрицу попарных скалярных произведений между объектами\n",
    "и точками можно с помощью одного матричного умножения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 2, 1, 2, 3, 1, 3, 1, 1, 1, 4, 1, 4, 4, 1, 1, 1, 1, 3, 3,\n",
       "       0, 1, 2, 1, 2, 1, 2, 0, 1, 2, 0, 1, 0, 2, 2, 0, 4, 2, 2, 2, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 4, 2, 0, 2, 1, 2, 2, 2, 0, 1, 1, 1, 1, 1, 2, 1,\n",
       "       2, 3, 2, 0, 3, 3, 2, 2, 1, 4, 1, 4, 1, 2, 0, 4, 2, 0, 3, 1, 1, 0, 4,\n",
       "       2, 2, 2, 2, 2, 3, 1, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA\n",
    "`x.cuda()` копирует тензор на GPU и возвращает объект, соответствующий этому скопированному тензору.\n",
    "Можно явно указать номер GPU, на который нужно скопировать тензор: `x.cuda(gpu_id)`.\n",
    "Если тензор уже лежал на нужном GPU, то возвращается сам тензор, копирования не производится.\n",
    "Аналогично работает `x.cpu()`. \n",
    "\n",
    "Операции можно осуществлять только над тензорами, лежащими на одном устройстве.\n",
    "Нарушение этого правила приводит к ошибке.\n",
    "Результат операции находится на том же устройстве, что и операнды."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor vs Variable\n",
    "\n",
    "http://pytorch.org/docs/master/autograd.html#variable\n",
    "\n",
    "`Variable` – обертка над Tensor для использования в вычислительных графах. Позволяет вычислять градиенты автоматически.\n",
    "\n",
    "Tensor и Variable конвертируются друг в друга:\n",
    "```\n",
    "tensor to variable: Variable(x)\n",
    "variable to tensor: x.data\n",
    "```\n",
    "\n",
    "Нельзя смешивать Tensor и Variable в одной операции.\n",
    "\n",
    "Некоторые операции могут работать только с тензорами, некоторые только с переменными (torch.nn.functional.whatever)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "sequence = torch.randn(1, 8, 10)\n",
    "filters = torch.randn(2, 8, 3)\n",
    "a = torch.randn(5)\n",
    "b = torch.randn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of Variables:\n",
      "tensor([-0.2437, -2.0920,  0.0834,  0.6123,  0.9017])\n"
     ]
    }
   ],
   "source": [
    "# works:\n",
    "print('sum of Variables:')\n",
    "print(Variable(a) + Variable(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of Variable and Tensor:\n",
      "tensor([-0.2437, -2.0920,  0.0834,  0.6123,  0.9017])\n"
     ]
    }
   ],
   "source": [
    "# will not work:\n",
    "print('sum of Variable and Tensor:')\n",
    "print(Variable(a) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1d over Variables:\n",
      "tensor([[[-17.2289,   6.9498,  -3.9531,   1.9001,  -2.3050,   2.5776,  -1.2697,\n",
      "            0.7694],\n",
      "         [  3.4654,  -5.3445,  -1.2298,   1.0513,  -3.1537,   3.9962,  -0.6860,\n",
      "            3.0355]]])\n"
     ]
    }
   ],
   "source": [
    "# works:\n",
    "print('conv1d over Variables:')\n",
    "print(torch.nn.functional.conv1d(Variable(sequence), Variable(filters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1d (tensors):\n",
      "tensor([[[-17.2289,   6.9498,  -3.9531,   1.9001,  -2.3050,   2.5776,  -1.2697,\n",
      "            0.7694],\n",
      "         [  3.4654,  -5.3445,  -1.2298,   1.0513,  -3.1537,   3.9962,  -0.6860,\n",
      "            3.0355]]])\n"
     ]
    }
   ],
   "source": [
    "# will not work\n",
    "print(\"conv1d (tensors):\")\n",
    "print(torch.nn.functional.conv1d(sequence, filters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic gradients\n",
    "\n",
    "Автоматическое вычисление градиентов:\n",
    "\n",
    "1. Создать переменную: `a = Variable(..., requires_grad=True)`\n",
    "\n",
    "2. Определить какую-нибудь дифференцируемую _скалярную_ функцию `loss = whatever(a)`\n",
    "\n",
    "3. Запросить обратный проход `loss.backward()`\n",
    "\n",
    "4. Градиенты будут доступны в `a.grads`\n",
    "\n",
    "\n",
    "Есть два важных отличия Pytorch от Theano/TF:\n",
    "\n",
    "1. Функцию ошибки можно изменять динамически, например на каждом минибатче.\n",
    "\n",
    "2. После вычисления `.backward()` градиенты сохраняются в `.grad` каждой задействованной переменной, при повторных вызовах градиенты суммируются. Это позволяет использовать несколько функций ошибок или виртуально увеличивать batch_size. Поэтому после каждого шага оптимизатора градиенты стоит обнулять."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простой пример использования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([ 1.1175, -0.5713,  0.8392,  0.7075])\n",
      "y: tensor([-0.9606,  1.3439, -2.1736,  0.4563])\n",
      "dp / dx: tensor([-0.9606,  1.3439, -2.1736,  0.4563])\n",
      "dp / dy: tensor([ 1.1175, -0.5713,  0.8392,  0.7075])\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.randn(4)\n",
    "y_tensor = torch.randn(4)\n",
    "x = Variable(x_tensor, requires_grad=True)\n",
    "y = Variable(y_tensor, requires_grad=True)\n",
    "z = x * y + 10\n",
    "p = z.sum()\n",
    "p.backward()\n",
    "print('x:', x.data)\n",
    "print('y:', y.data)\n",
    "print('dp / dx:', x.grad.data)\n",
    "print('dp / dy:', y.grad.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обнуление градиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [ 1.  1.  1.  1.]\n",
      "dp / dx: [ 2.  2.  2.  2.]\n",
      "x: [ 0.5  0.5  0.5  0.5]\n",
      "dp / dx: [-2. -2. -2. -2.]\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.Tensor([1, 1, 1, 1])\n",
    "x = Variable(x_tensor, requires_grad=True)\n",
    "y = x ** 2\n",
    "p = y.sum()\n",
    "p.backward()\n",
    "print('x:', x.data.numpy())\n",
    "print('dp / dx:', x.grad.data.numpy())\n",
    "x.data -= 0.5\n",
    "y = 1 / x\n",
    "p = y.sum()\n",
    "p.backward()\n",
    "print('x:', x.data.numpy())\n",
    "print('dp / dx:', x.grad.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [ 1.  1.  1.  1.]\n",
      "dp / dx: [ 2.  2.  2.  2.]\n",
      "x: [ 0.5  0.5  0.5  0.5]\n",
      "dp / dx: [-4. -4. -4. -4.]\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.Tensor([1, 1, 1, 1])\n",
    "x = Variable(x_tensor, requires_grad=True)\n",
    "y = x ** 2\n",
    "p = y.sum()\n",
    "p.backward()\n",
    "print('x:', x.data.numpy())\n",
    "print('dp / dx:', x.grad.data.numpy())\n",
    "x.grad.detach_()       # extracting gradient Variable from the previous computational graph (optional)\n",
    "x.grad.data.zero_()    # zero gradinents\n",
    "x.data -= 0.5\n",
    "y = 1 / x\n",
    "p = y.sum()\n",
    "p.backward()\n",
    "print('x:', x.data.numpy())\n",
    "print('dp / dx:', x.grad.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaf vs Non-leaf Variable\n",
    "\n",
    "Градиенты будут сохранены и доступны для использования только для `leaf-variable`.\n",
    "Такое поведение по умолчанию сделано ради экономии памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.data: [-0.37733507  0.31175423 -0.4395192   0.24251799]\n",
      "y.data: [ 0.62266493  1.31175423  0.56048083  1.24251795]\n",
      "p.data: 3.7374179363250732\n",
      "x.grad: [ 1.  1.  1.  1.]\n",
      "y.grad: None\n",
      "p.grad: None\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(4), requires_grad=True)  # leaf variable\n",
    "y = x + 1                                         # not a leaf variable\n",
    "p = y.sum()                                       # not a leaf variable\n",
    "p.backward()\n",
    "print('x.data:', x.data.numpy())\n",
    "print('y.data:', y.data.numpy())\n",
    "print('p.data:', p.data.numpy())\n",
    "print('x.grad:', x.grad.data.numpy())\n",
    "print('y.grad:', y.grad)\n",
    "print('p.grad:', p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad: [ 1.  1.  1.  1.]\n",
      "y.grad: [ 1.  1.  1.  1.]\n",
      "z.grad: None\n",
      "p.grad: None\n",
      "x.is_leaf: True\n",
      "y.is_leaf: True\n",
      "z.is_leaf: False\n",
      "p.is_leaf: False\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(4), requires_grad=True)  # leaf variable\n",
    "y = Variable(torch.randn(4), requires_grad=True)  # leaf variable\n",
    "z = x + y    # not a leaf variable\n",
    "p = z.sum()  # not a leaf variable\n",
    "p.backward()\n",
    "print('x.grad:', x.grad.data.numpy())\n",
    "print('y.grad:', y.grad.data.numpy())\n",
    "print('z.grad:', z.grad)\n",
    "print('p.grad:', p.grad)\n",
    "print('x.is_leaf:', x.is_leaf)\n",
    "print('y.is_leaf:', y.is_leaf)\n",
    "print('z.is_leaf:', z.is_leaf)\n",
    "print('p.is_leaf:', p.is_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Листовые вершины без градиентов\n",
    "Листовые вершины, в которых не требуется вычислять градиент, создаются с помощью `Variable(..., requires_grad=False)`.\n",
    "Для корректного вызова `.backward()` требуется, чтобы хотя бы для одной листовой вершины требовался градиент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad: [ 1.  1.  1.  1.]\n",
      "y.grad: None\n",
      "z.grad: None\n",
      "p.grad: None\n",
      "x.is_leaf: True\n",
      "y.is_leaf: True\n",
      "z.is_leaf: False\n",
      "p.is_leaf: False\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(4), requires_grad=True)   # leaf variable\n",
    "y = Variable(torch.randn(4), requires_grad=False)  # leaf variable\n",
    "z = x + y    # not a leaf variable\n",
    "p = z.sum()  # not a leaf variable\n",
    "p.backward()\n",
    "print('x.grad:', x.grad.data.numpy())\n",
    "print('y.grad:', y.grad)\n",
    "print('z.grad:', z.grad)\n",
    "print('p.grad:', p.grad)\n",
    "print('x.is_leaf:', x.is_leaf)\n",
    "print('y.is_leaf:', y.is_leaf)\n",
    "print('z.is_leaf:', z.is_leaf)\n",
    "print('p.is_leaf:', p.is_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что для вычисления градиента нужно, чтобы хотя бы одна листовая вершина графа вычисления функции\n",
    "имела `requires_grad=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1a8a06cd070e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m    \u001b[0;31m# not a leaf variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# not a leaf variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# will not work:\n",
    "x = Variable(torch.randn(4), requires_grad=False)  # leaf variable\n",
    "y = Variable(torch.randn(4), requires_grad=False)  # leaf variable\n",
    "z = x + y    # not a leaf variable\n",
    "p = z.sum()  # not a leaf variable\n",
    "p.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиенты промежуточных вершин\n",
    "Для промежуточных вершин мы можем запросить сохранение градиентов с помощью функции `.retain_grad()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp / dx: [ 1.92757583 -2.2354784   1.24162018  2.519238  ]\n",
      "dp / dw: [ 0.79092884 -0.35837969 -1.23274362  0.46698242]\n",
      "dp / dz: [ 1.58185768 -0.71675938 -2.46548724  0.93396485]\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(4), requires_grad=True)   # leaf variable\n",
    "z = Variable(torch.randn(4), requires_grad=True)   # leaf variable\n",
    "w = z * 2      # not a leaf variable\n",
    "y = x * w + 1  # forward pass before retaining gradient is ok\n",
    "p = y.sum()\n",
    "\n",
    "w.retain_grad()\n",
    "\n",
    "p.backward()\n",
    "print('dp / dx:', x.grad.data.numpy())\n",
    "print('dp / dw:', w.grad.data.numpy())\n",
    "print('dp / dz:', z.grad.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим внимание, что даже при наличии в графе вычислений не-листовых вершин, требующих вычисления градиентов,\n",
    "`.backward()` выдает ошибку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of variables does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-03d569ff82b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/soft/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/soft/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of variables does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# will not work\n",
    "x = Variable(torch.randn(4), requires_grad=False)   # leaf variable\n",
    "z = Variable(torch.randn(4), requires_grad=False)   # leaf variable\n",
    "w = z * 2      # not a leaf variable\n",
    "y = x * w + 1  # forward pass before retaining gradient is ok\n",
    "p = y.sum()\n",
    "\n",
    "w.retain_grad()\n",
    "\n",
    "p.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отстреливаем себе ноги (НЕ НАДО так делать)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конвертировать Variable в Tensor и обратно:\n",
    "backward pass не проходит через Tensor, даже если он был сконвертирован из другого Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp / dx: None\n",
      "dp / dy: [ 0.75  0.75  0.75  0.75]\n"
     ]
    }
   ],
   "source": [
    "# x out of the computational graph\n",
    "x = torch.autograd.Variable(torch.Tensor([1, 2, 3, 4]), requires_grad=True)\n",
    "y = torch.autograd.Variable(x.data * 2, requires_grad=True)   # the bad conversion is here\n",
    "z = 3 * y + 1\n",
    "p = z.mean()\n",
    "p.backward()\n",
    "print('dp / dx:', x.grad)\n",
    "print('dp / dy:', y.grad.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Менять размерность тензоров в Variable, но не обнулять градиенты (`.grad.zero_()` сохраняет размер, `.grad = None` не сохраняет)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dz / dx: [ 1.  2.  3.  4.]\n",
      "dz / dy: [ 1.  2.  3.  4.]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'zero_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5aa15072c346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#x.grad = None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#z.grad = None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'zero_'"
     ]
    }
   ],
   "source": [
    "x = torch.autograd.Variable(torch.Tensor([1, 2, 3, 4]), requires_grad=True)\n",
    "y = torch.autograd.Variable(torch.Tensor([1, 2, 3, 4]), requires_grad=True)\n",
    "z = x * y + 1\n",
    "z.sum().backward()\n",
    "print('dz / dx:', x.grad.data.numpy())\n",
    "print('dz / dy:', y.grad.data.numpy())\n",
    "\n",
    "x.grad.zero_()\n",
    "z.grad.zero_()\n",
    "#x.grad = None\n",
    "#z.grad = None\n",
    "\n",
    "x.data = torch.Tensor([1, 2, 3])\n",
    "y.data = torch.Tensor([1, 2, 3])\n",
    "z = x * y + 1\n",
    "z.sum().backward()\n",
    "print('dz / dx:', x.grad.data.numpy())\n",
    "print('dz / dy:', y.grad.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Менять значения Variable после вычисления каких-то других выражений с ним и рассчитывать,\n",
    "что градиент от тех выражений будет учитывать новое значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d p_sum / dx: [ 1.  2.  3.  4.]\n",
      "d p_sum / dy: [  2.   8.  18.  32.]\n"
     ]
    }
   ],
   "source": [
    "x = torch.autograd.Variable(torch.Tensor([1, 2, 3, 4]), requires_grad=True)\n",
    "y = torch.autograd.Variable(torch.Tensor([1, 2, 3, 4]), requires_grad=True)\n",
    "z = y ** 2\n",
    "\n",
    "z.data = torch.Tensor([1, 2, 3, 4])  # changing .data before computation matters\n",
    "p = x * z\n",
    "x.data = torch.Tensor([1, 1, 1])     # changing .data after computation doesn't affect gradients\n",
    "\n",
    "p.sum().backward()\n",
    "print('d p_sum / dx:', x.grad.data.numpy())\n",
    "print('d p_sum / dy:', y.grad.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тысячи способов прострелить себе ногу, если использовать механизм автоматического дифференцирования\n",
    "любым другим нетрадиционным образом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = torch.randn(50, 10)\n",
    "b = torch.randn(2)\n",
    "W = torch.randn(10, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наркоманская функция потерь, вынуждающая линейное преобразование переводить точки из многомерного пространства в двумерное на единичную окружность. Для оптимизации использовать градиентный спуск по параметрам преобразования.\n",
    "\n",
    "Линейное преобразование точки $x$ из десятимерного пространства в точку $y$ двумерного пространства с весами преобразования $W$ и $b$:\n",
    "$$y = Wx + b$$\n",
    "\n",
    "Норма в двумерном пространстве – евклидова:\n",
    "$$||y||_2 = \\sqrt{y_1^2 + y_2^2}$$\n",
    "\n",
    "Функция потерь $f_0$ штрафует расстояние от получившейся точки $y$ до единичной окружности:\n",
    "$$f_0(x, W, b) = 0.5 \\cdot \\big| ||y||_2 - 1 \\big| + \\big( ||y||_2 - 1 \\big)^2$$\n",
    "\n",
    "К сожалению, оптимизация функции $f_0$ по $W$ и $b$ может быть проведена аналитически\n",
    "и приводит к тривиальному решению $W = 0$, $b = (1, 0)$.\n",
    "Чтобы избежать такого решения, вводим штраф на близость получившейся точки к вектору $b$, который обращается в 0, если расстояние до вектора $b$ более 1:\n",
    "$$f_1(x, W, b) = \\max\\big(0, \\frac{1}{||y - b||_2} - 1\\big)$$\n",
    "\n",
    "Итоговая функция потерь:\n",
    "$$f(x, W, b) = f_0(x, W, b) + f_1(x, W, b)$$\n",
    "\n",
    "Нужно решить следующую оптимизационную задачу:\n",
    "$$\\frac{1}{N}\\sum\\limits_{i = 1}^N f(x_i, W, b) \\to \\min\\limits_{W, b}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(X, W, b):\n",
    "    y = X.mm(W).add(b)\n",
    "    ynorm2 = y.norm(dim=-1)\n",
    "    print(ynorm2.numpy() == torch.sqrt(y**2).mean(-1).numpy())\n",
    "    f0 = 0.5 * torch.abs(ynorm2 - 1) + (ynorm2 - 1)**2\n",
    "    f1 = max(0, (1/(torch.norm(y-b))) - 1)\n",
    "    return torch.mean(f0 + f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "norm() received an invalid combination of arguments - got (keepdim=bool, ), but expected one of:\n * (Number p)\n      didn't match because some of the keywords were incorrect: keepdim\n * (Number p, int dim, bool keepdim)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-9b38224e71a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-a88704284288>\u001b[0m in \u001b[0;36mf\u001b[0;34m(X, W, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mynorm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mynorm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mynorm2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mynorm2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: norm() received an invalid combination of arguments - got (keepdim=bool, ), but expected one of:\n * (Number p)\n      didn't match because some of the keywords were incorrect: keepdim\n * (Number p, int dim, bool keepdim)\n"
     ]
    }
   ],
   "source": [
    "print(f(X, W, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x104189080>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEyCAYAAABj+rxLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f63dc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "Y = X.mm(W).add(b)\n",
    "plt.scatter(Y[:, 0], Y[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842589\n",
      "0.363394\n",
      "0.307726\n",
      "0.278642\n",
      "0.262647\n",
      "0.244216\n",
      "0.222634\n",
      "0.205349\n",
      "0.197059\n",
      "0.193335\n"
     ]
    }
   ],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7fe22b0320>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEyCAYAAACYrUmUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHzNV2ksxZytnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fe22cb550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "Y = X.mm(W).add(b)\n",
    "plt.scatter(Y[:, 0], Y[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Время писать нейросеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1347, 64), (450, 64))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсказка: нейросети крайне плохо обучаются, если подаваемые им на вход значения велики по модулю.\n",
    "Поэтому перед обучением нейросети каждый признак независимо нормируют\n",
    "(исключение – сверточные нейросети, там нормируют изображение поканально, а не попиксельно, но об этом потом).\n",
    "\n",
    "Можно использовать разные нормировки.\n",
    "Наиболее популярно вычитать среднее и делить на дисперсию (нужно внимательно подходить к этому методу,\n",
    "когда выборочная дисперсия мала или равна нулю, и обрабатывать такие случаи отдельно).\n",
    "Можно также вычитать медиану и делить на интерквартильный размах, масштабировать все данные в отрезок $[-1, 1]$, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно реализовать свою нормировку данных здесь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определяем слои нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self.training = True\n",
    "        self.children = []\n",
    "\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"Returns list of parameters of module and its children.\"\"\"\n",
    "        res = []\n",
    "        for submodule in self.children:\n",
    "            res += submodule.parameters()\n",
    "        for param in res:\n",
    "            if not isinstance(param, Variable):\n",
    "                raise Exception('Parameters must be Variables.')\n",
    "        return res\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"Sets gradients of all model parameters to zero.\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.grad is not None:\n",
    "                p.grad.detach_()   # detachs gradient Variable from the computational graph\n",
    "                p.grad.zero_()\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Sets module into train mode (for DropOut, BatchNorm, etc).\"\"\"\n",
    "        self.training = True\n",
    "        for submodule in self.children:\n",
    "            submodule.train()\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"Sets module into evaluation mode.\"\"\"\n",
    "        self.training = False\n",
    "        for submodule in self.children:\n",
    "            submodule.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dense(Module):\n",
    "    def __init__(self, input_units, output_units):\n",
    "        \"\"\"A dense layer is a layer which performs a learned affine transformation:\n",
    "        f(x) = W x + b\n",
    "        \"\"\"\n",
    "        super(Dense, self).__init__()\n",
    "        # initialize weights with small random numbers from normal distribution\n",
    "        self.weights = None  # your code here\n",
    "        self.biases = None   # your code here\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weights, self.biases]\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \"\"\"Performs an affine transformation:\n",
    "        f(x) = W x + b\n",
    "        input shape:  [batch, input_units]  (Variable)\n",
    "        output shape: [batch, output units] (Variable)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReLU(Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"ReLU layer simply applies elementwise rectified linear unit to all inputs.\"\"\"\n",
    "        super(ReLU, self).__init__()\n",
    "\n",
    "    def parameters(self):\n",
    "        return []  # ReLU has no parameters\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"Applies elementwise ReLU to [batch, num_units] Variable matrix.\"\"\"\n",
    "        # your code here\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogSoftmax(Module):\n",
    "    def __init__(self):\n",
    "        super(LogSoftmax, self).__init__()\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \"\"\"Applies softmax to each row and then applies component-wise log.\n",
    "        Input shape:  [batch, num_units] (Variable)\n",
    "        Output shape: [batch, num_units] (Variable)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyNetwork(Module):\n",
    "    def __init__(self, input_size, hidden_layers_size, hidden_layers_number, output_size):\n",
    "        super(MyNetwork, self).__init__()\n",
    "\n",
    "        network = []\n",
    "        network.append(Dense(input_size, hidden_layers_size))\n",
    "        network.append(ReLU())\n",
    "        for i in range(hidden_layers_number - 1):\n",
    "            network.append(Dense(hidden_layers_size, hidden_layers_size))\n",
    "            network.append(ReLU())\n",
    "        network.append(Dense(hidden_layers_size, output_size))\n",
    "        network.append(LogSoftmax())\n",
    "\n",
    "        self.children = network\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Applies all layers of neural network to the input.\n",
    "        Input shape:  [batch, num_units] (Variable)\n",
    "        Output shape: [batch, num_units] (Variable)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = MyNetwork(X_train.shape[1], 32, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определяем функцию потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossentropy(activations, target):\n",
    "    \"\"\"Returns negative log-likelihood of target under model\n",
    "    represented by activations (log probabilities of classes).\n",
    "    Activations shape: [batch, num_classes] (Variable)\n",
    "    Target shape:      [batch]              (Variable)\n",
    "    Output shape: 1 (scalar, Variable)\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оптимизатор SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SGDOptimizer:\n",
    "    def __init__(self, parameters, learning_rate):\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Make one optimization step for parameters in-place.\n",
    "        Assumes that all parameters are Variable with computed gradient.\n",
    "        \"\"\"\n",
    "        for param in self.parameters:\n",
    "            param.data -= self.learning_rate * param.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(dataset, network, prefix='Test loss:', optimizer=None):\n",
    "    # Change mode for all layers.\n",
    "    if optimizer:\n",
    "        network.train()\n",
    "    else:\n",
    "        network.eval()\n",
    "\n",
    "    batch_size = 100\n",
    "    batchgenerator = torch.utils.data.DataLoader(dataset, batch_size, True)\n",
    "\n",
    "    avg_loss = 0\n",
    "    for i, (batch_data, batch_target) in enumerate(batchgenerator):\n",
    "        batch_output = network.forward(Variable(batch_data))\n",
    "        batch_loss = crossentropy(batch_output, Variable(batch_target))\n",
    "        batch_loss.backward()\n",
    "        batch_loss = batch_loss.data.numpy()[0]\n",
    "        avg_loss += (batch_loss - avg_loss) / (i + 1)\n",
    "        if optimizer:\n",
    "            optimizer.step()\n",
    "            network.zero_grad()\n",
    "    print(prefix, avg_loss, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.25001299381\n",
      "Test loss: 2.02255702019\n",
      "Train loss: 0.935892488275\n",
      "Test loss: 0.526892650127\n",
      "Train loss: 0.311101637781\n",
      "Test loss: 0.224462372065\n",
      "Train loss: 0.162839947534\n",
      "Test loss: 0.137114882469\n",
      "Train loss: 0.116679061204\n",
      "Test loss: 0.100092953444\n",
      "Train loss: 0.0960424696761\n",
      "Test loss: 0.0819583252072\n",
      "Train loss: 0.0743240392102\n",
      "Test loss: 0.0691537447274\n",
      "Train loss: 0.0632074608334\n",
      "Test loss: 0.0648413747549\n",
      "Train loss: 0.0556773274605\n",
      "Test loss: 0.0526380605996\n",
      "Train loss: 0.0497626392171\n",
      "Test loss: 0.0536358714104\n",
      "Train loss: 0.0436364341793\n",
      "Test loss: 0.0415103141218\n",
      "Train loss: 0.0387461567963\n",
      "Test loss: 0.0370218373835\n",
      "Train loss: 0.0330237374375\n",
      "Test loss: 0.0317714843899\n",
      "Train loss: 0.0313186772567\n",
      "Test loss: 0.0290575809777\n",
      "Train loss: 0.0266977072959\n",
      "Test loss: 0.0287078157067\n",
      "Train loss: 0.0241593799022\n",
      "Test loss: 0.0236087350175\n",
      "Train loss: 0.0228125809559\n",
      "Test loss: 0.0228643067181\n",
      "Train loss: 0.0213984650826\n",
      "Test loss: 0.0240131534636\n",
      "Train loss: 0.0181131877138\n",
      "Test loss: 0.0180235758424\n",
      "Train loss: 0.0175916215937\n",
      "Test loss: 0.0181138986722\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "network = MyNetwork(X_train.shape[1], 32, 1, 10)\n",
    "sgd = SGDOptimizer(network.parameters(), 0.5)\n",
    "\n",
    "num_epochs = 20\n",
    "for i in range(num_epochs):\n",
    "    run_epoch(train_dataset, network, 'Train loss:', sgd)\n",
    "    run_epoch(test_dataset, network, 'Test loss:',  None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Больше оптимизаторов Б-гу Оптимизации!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SGDMomentumOptimizer:\n",
    "    def __init__(self, parameters, learning_rate=0.01, momentum=0.9):\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        # your code here\n",
    "        \n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Make one optimization step for parameters in-place.\n",
    "        Assumes that all parameters are Variable with computed gradient.\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RMSPropOptimizer:\n",
    "    def __init__(self, parameters, learning_rate=0.01, beta=0.9, eps=1e-8):\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta = beta\n",
    "        self.eps = eps\n",
    "        # your code here\n",
    "        \n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Make one optimization step for parameters in-place.\n",
    "        Assumes that all parameters are Variable with computed gradient.\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdamOptimizer:\n",
    "    def __init__(self, parameters, learning_rate=0.01, beta1=0.9, beta2=0.999, eps=1e-8):\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        # your code here\n",
    "        \n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Make one optimization step for parameters in-place.\n",
    "        Assumes that all parameters are Variable with computed gradient.\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.29899907112\n",
      "Test loss: 2.28840465546\n",
      "Train loss: 2.17900568247\n",
      "Test loss: 1.91997365952\n",
      "Train loss: 1.19421473571\n",
      "Test loss: 0.793489205837\n",
      "Train loss: 0.455302154379\n",
      "Test loss: 0.312181121111\n",
      "Train loss: 0.230511957513\n",
      "Test loss: 0.165832227468\n",
      "Train loss: 0.123873262533\n",
      "Test loss: 0.100607940555\n",
      "Train loss: 0.0892768991845\n",
      "Test loss: 0.0810534343123\n",
      "Train loss: 0.0676086062033\n",
      "Test loss: 0.0628551796079\n",
      "Train loss: 0.0543780475855\n",
      "Test loss: 0.0540404502302\n",
      "Train loss: 0.0464387893943\n",
      "Test loss: 0.0465289611369\n",
      "Train loss: 0.040847371798\n",
      "Test loss: 0.0428905472159\n",
      "Train loss: 0.037239708339\n",
      "Test loss: 0.0359449528158\n",
      "Train loss: 0.0327466359096\n",
      "Test loss: 0.0366176884621\n",
      "Train loss: 0.0296002742834\n",
      "Test loss: 0.0310783546418\n",
      "Train loss: 0.0265897470526\n",
      "Test loss: 0.0265863619745\n",
      "Train loss: 0.0248268215385\n",
      "Test loss: 0.0258533308282\n",
      "Train loss: 0.0228131134063\n",
      "Test loss: 0.0230030672625\n",
      "Train loss: 0.0207394263042\n",
      "Test loss: 0.0255728438497\n",
      "Train loss: 0.0193641397969\n",
      "Test loss: 0.0202927647159\n",
      "Train loss: 0.0178717284996\n",
      "Test loss: 0.0180073000491\n"
     ]
    }
   ],
   "source": [
    "network = MyNetwork(X_train.shape[1], 32, 1, 10)\n",
    "optim = SGDMomentumOptimizer(network.parameters(), 0.5)\n",
    "\n",
    "num_epochs = 20\n",
    "for i in range(num_epochs):\n",
    "    run_epoch(train_dataset, network, 'Train loss:', optim)\n",
    "    run_epoch(test_dataset, network, 'Test loss:',  None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.04873784099\n",
      "Test loss: 0.38672837019\n",
      "Train loss: 0.227099137647\n",
      "Test loss: 0.188070484996\n",
      "Train loss: 0.132430793984\n",
      "Test loss: 0.121710123122\n",
      "Train loss: 0.0845916050353\n",
      "Test loss: 0.0908883780241\n",
      "Train loss: 0.0581328541573\n",
      "Test loss: 0.0690488003194\n",
      "Train loss: 0.0373754860567\n",
      "Test loss: 0.0434633551165\n",
      "Train loss: 0.0285121881004\n",
      "Test loss: 0.0349668972194\n",
      "Train loss: 0.0181794009903\n",
      "Test loss: 0.0249595091678\n",
      "Train loss: 0.0139850968761\n",
      "Test loss: 0.0204672420397\n",
      "Train loss: 0.0095160015127\n",
      "Test loss: 0.019333433453\n",
      "Train loss: 0.00756529153192\n",
      "Test loss: 0.0102690941188\n",
      "Train loss: 0.00454936275491\n",
      "Test loss: 0.0070749043487\n",
      "Train loss: 0.00344879847918\n",
      "Test loss: 0.00430776766734\n",
      "Train loss: 0.00373204343902\n",
      "Test loss: 0.00334942489862\n",
      "Train loss: 0.00152089097537\n",
      "Test loss: 0.00197805096395\n",
      "Train loss: 0.0013455981264\n",
      "Test loss: 0.00142132241745\n",
      "Train loss: 0.000820027600899\n",
      "Test loss: 0.000827933556866\n",
      "Train loss: 0.000583214284104\n",
      "Test loss: 0.000719902419951\n",
      "Train loss: 0.000449190720766\n",
      "Test loss: 0.000355705589755\n",
      "Train loss: 0.000906572375243\n",
      "Test loss: 0.000387026541284\n"
     ]
    }
   ],
   "source": [
    "network = MyNetwork(X_train.shape[1], 32, 1, 10)\n",
    "optim = RMSPropOptimizer(network.parameters())\n",
    "\n",
    "num_epochs = 20\n",
    "for i in range(num_epochs):\n",
    "    run_epoch(train_dataset, network, 'Train loss:', optim)\n",
    "    run_epoch(test_dataset, network, 'Test loss:',  None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.984752461314\n",
      "Test loss: 0.311784574389\n",
      "Train loss: 0.334625060537\n",
      "Test loss: 0.129556299746\n",
      "Train loss: 0.147239101785\n",
      "Test loss: 0.13299726136\n",
      "Train loss: 0.0741345614993\n",
      "Test loss: 0.0770199432969\n",
      "Train loss: 0.0687923396805\n",
      "Test loss: 0.190458774939\n",
      "Train loss: 0.0397689110999\n",
      "Test loss: 0.0965252541006\n",
      "Train loss: 0.0178003121567\n",
      "Test loss: 0.040087666316\n",
      "Train loss: 0.0105867093745\n",
      "Test loss: 0.0139437015634\n",
      "Train loss: 0.00589249691049\n",
      "Test loss: 0.00134194488637\n",
      "Train loss: 0.00215421384616\n",
      "Test loss: 0.00138041300233\n",
      "Train loss: 0.00115795526654\n",
      "Test loss: 0.000901157624321\n",
      "Train loss: 0.000817922378441\n",
      "Test loss: 0.000593731965637\n",
      "Train loss: 0.00073160989684\n",
      "Test loss: 0.000453838970861\n",
      "Train loss: 0.000624272052456\n",
      "Test loss: 0.000451174081536\n",
      "Train loss: 0.000591980269486\n",
      "Test loss: 0.00039646657533\n",
      "Train loss: 0.000536981753872\n",
      "Test loss: 0.000367731397273\n",
      "Train loss: 0.000519900157607\n",
      "Test loss: 0.000337578472681\n",
      "Train loss: 0.000461065433878\n",
      "Test loss: 0.000309497537091\n",
      "Train loss: 0.000445698657651\n",
      "Test loss: 0.000284600986197\n",
      "Train loss: 0.000420782158991\n",
      "Test loss: 0.000307945412351\n"
     ]
    }
   ],
   "source": [
    "network = MyNetwork(X_train.shape[1], 32, 1, 10)\n",
    "optim = AdamOptimizer(network.parameters())\n",
    "\n",
    "num_epochs = 20\n",
    "for i in range(num_epochs):\n",
    "    run_epoch(train_dataset, network, 'Train loss:', optim)\n",
    "    run_epoch(test_dataset, network, 'Test loss:',  None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эксперименты с DropOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот пункт обязателен к выполнению.\n",
    "Для того, чтобы получить бонусный балл за этот пункт, нужно эффективно реализовать DropOut:\n",
    "не вычислять активации выкинутых нейронов, прежде чем их обнулить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseWithDropOut(Module):\n",
    "    def __init__(self, input_units, output_units, dropout_rate, nonlinearity):\n",
    "        \"\"\"A dense layer is a layer which performs a learned\n",
    "        affine transformation and applies dropout:\n",
    "        m ~ Bernoulli(1 - p, size=output_units)\n",
    "        f(x) = g(W x + b) o m\n",
    "        \"\"\"\n",
    "        super(DenseWithDropOut, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.nonlinearity = nonlinearity\n",
    "        # initialize weights with small random numbers from normal distribution\n",
    "        self.weights = None  # your code here\n",
    "        self.biases = None   # your code here\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weights, self.biases]\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \"\"\"Performs an affine transformation with dropout.\n",
    "        In training mode:\n",
    "        m ~ Bernoulli(1 - p, size=output_units)\n",
    "        f(x) = g(W x + b) o m\n",
    "        In evaluation mode:\n",
    "        f(x) = g(W x + b) (1 - p)\n",
    "        input shape:  [batch, input_units]  (Variable)\n",
    "        output shape: [batch, output units] (Variable)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем, верно ли, что полносвязная сеть с dropout работает быстрее, чем обычная полносвязная сеть, поскольку на каждом проходе вычисляются произведения матриц меньшего размера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.54 s ± 191 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "7.3 s ± 954 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "width = 2000\n",
    "network1 = [\n",
    "    DenseWithDropOut(width, width, 0.9, lambda x: ReLU().forward(x)),\n",
    "    DenseWithDropOut(width, width, 0.9, lambda x: ReLU().forward(x)),\n",
    "    DenseWithDropOut(width, width, 0.9, lambda x: ReLU().forward(x)),\n",
    "    DenseWithDropOut(width, 1, 0, lambda x: x)\n",
    "]\n",
    "network2 = [\n",
    "    Dense(width, width),\n",
    "    ReLU(),\n",
    "    Dense(width, width),\n",
    "    ReLU(),\n",
    "    Dense(width, width),\n",
    "    ReLU(),\n",
    "    Dense(width, 1)\n",
    "]\n",
    "X = torch.randn(10000, width)\n",
    "\n",
    "# check whether DenseWithDropOut works faster than Dense\n",
    "def test_network(network):\n",
    "    x = Variable(X)\n",
    "    for layer in network:\n",
    "        x = layer.forward(x)\n",
    "    x.mean().backward()\n",
    "    for layer in network:\n",
    "        x = layer.zero_grad()\n",
    "\n",
    "test_network(network1)\n",
    "%timeit test_network(network1)\n",
    "%timeit test_network(network2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для более узких слоев, меньших dropout rate и меньших размеров батча увеличение производительности не настолько существенно или может вообще отсутствовать."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
